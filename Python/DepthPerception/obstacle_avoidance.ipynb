{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "# source : https://learnopencv.com/depth-perception-using-stereo-camera-python-c/\n",
    "# https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera\n",
    "\n",
    "# Check for left and right camera IDs\n",
    "# These values can change depending on the system\n",
    "left_source = \"nvarguscamerasrc sensor-id=0 sensor-mode=3 ! video/x-raw(memory:NVMM), width=(int)640, height=(int)480, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv flip-method=2 ! video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\"\n",
    "right_source = \"nvarguscamerasrc sensor-id=1 sensor-mode=3 ! video/x-raw(memory:NVMM), width=(int)640, height=(int)480, format=(string)NV12, framerate=(fraction)30/1 ! nvvidconv flip-method=2 ! video/x-raw, width=(int)640, height=(int)480, format=(string)BGRx ! videoconvert ! video/x-raw, format=(string)BGR ! appsink\"\n",
    "\n",
    "# To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "CamL = cv2.VideoCapture(left_source, cv2.CAP_GSTREAMER)\n",
    "if not CamL.isOpened():\n",
    "    print(\"Unable to open camera Left\")\n",
    "\n",
    "# To flip the image, modify the flip_method parameter (0 and 2 are the most common)\n",
    "CamR = cv2.VideoCapture(right_source, cv2.CAP_GSTREAMER)\n",
    "if not CamR.isOpened():\n",
    "    print(\"Unable to open camera Right\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the mapping values for stereo image rectification\n",
    "cv_file = cv2.FileStorage(\"./data/stereo_rectify_maps.xml\", cv2.FILE_STORAGE_READ)\n",
    "Left_Stereo_Map_x = cv_file.getNode(\"Left_Stereo_Map_x\").mat()\n",
    "Left_Stereo_Map_y = cv_file.getNode(\"Left_Stereo_Map_y\").mat()\n",
    "Right_Stereo_Map_x = cv_file.getNode(\"Right_Stereo_Map_x\").mat()\n",
    "Right_Stereo_Map_y = cv_file.getNode(\"Right_Stereo_Map_y\").mat()\n",
    "cv_file.release()\n",
    "\n",
    "disparity = None\n",
    "depth_map = None\n",
    "\n",
    "# These parameters can vary according to the setup\n",
    "max_depth = 200  # maximum distance the setup can measure (in cm)\n",
    "min_depth = 5  # minimum distance the setup can measure (in cm)\n",
    "depth_thresh = 50.0  # Threshold for SAFE distance (in cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the stored the StereoBM parameters\n",
    "cv_file = cv2.FileStorage(\"./data/depth_estmation_params_py.xml\", cv2.FILE_STORAGE_READ)\n",
    "numDisparities = int(cv_file.getNode(\"numDisparities\").real())\n",
    "blockSize = int(cv_file.getNode(\"blockSize\").real())\n",
    "preFilterType = int(cv_file.getNode(\"preFilterType\").real())\n",
    "preFilterSize = int(cv_file.getNode(\"preFilterSize\").real())\n",
    "preFilterCap = int(cv_file.getNode(\"preFilterCap\").real())\n",
    "textureThreshold = int(cv_file.getNode(\"textureThreshold\").real())\n",
    "uniquenessRatio = int(cv_file.getNode(\"uniquenessRatio\").real())\n",
    "speckleRange = int(cv_file.getNode(\"speckleRange\").real())\n",
    "speckleWindowSize = int(cv_file.getNode(\"speckleWindowSize\").real())\n",
    "disp12MaxDiff = int(cv_file.getNode(\"disp12MaxDiff\").real())\n",
    "minDisparity = int(cv_file.getNode(\"minDisparity\").real())\n",
    "M = cv_file.getNode(\"M\").real()\n",
    "cv_file.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse callback function\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global Z\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        print(\"Distance = %.2f cm\" % depth_map[y, x])\n",
    "\n",
    "\n",
    "cv2.namedWindow('disp', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('disp', 600, 600)\n",
    "cv2.setMouseCallback('disp', mouse_click)\n",
    "\n",
    "output_canvas = None\n",
    "\n",
    "# Creating an object of StereoBM algorithm\n",
    "stereo = cv2.StereoBM_create()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoid():\n",
    "    # Mask to segment regions with depth less than threshold\n",
    "    mask = cv2.inRange(depth_map, 10, depth_thresh)\n",
    "\n",
    "    # Check if a significantly large obstacle is present and filter out smaller noisy regions\n",
    "    if np.sum(mask) / 255.0 > 0.01 * mask.shape[0] * mask.shape[1]:\n",
    "\n",
    "        # Contour detection\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Check if detected contour is significantly large (to avoid multiple tiny regions)\n",
    "        if cv2.contourArea(cnts[0]) > 0.01 * mask.shape[0] * mask.shape[1]:\n",
    "            x, y, w, h = cv2.boundingRect(cnts[0])\n",
    "\n",
    "            # finding average depth of region represented by the largest contour\n",
    "            mask2 = np.zeros_like(mask)\n",
    "            cv2.drawContours(mask2, cnts, 0, (255), -1)\n",
    "\n",
    "            # Calculating the average depth of the object closer than the safe distance\n",
    "            depth_mean, _ = cv2.meanStdDev(depth_map, mask=mask2)\n",
    "\n",
    "            # Display warning text\n",
    "            cv2.putText(output_canvas, \"WARNING !\", (x + 5, y - 40), 1, 2, (0, 0, 255), 2, 2)\n",
    "            cv2.putText(output_canvas, \"Object at\", (x + 5, y), 1, 2, (100, 10, 25), 2, 2)\n",
    "            cv2.putText(output_canvas, \"%.2f cm\" % depth_mean, (x + 5, y + 40), 1, 2, (100, 10, 25), 2, 2)\n",
    "\n",
    "    else:\n",
    "        cv2.putText(output_canvas, \"SAFE!\", (100, 100), 1, 3, (0, 255, 0), 2, 3)\n",
    "\n",
    "    cv2.imshow('output_canvas', output_canvas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    retR, imgR = CamR.read()\n",
    "    retL, imgL = CamL.read()\n",
    "\n",
    "    if retL and retR:\n",
    "\n",
    "        output_canvas = imgL.copy()\n",
    "\n",
    "        imgR_gray = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "        imgL_gray = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Applying stereo image rectification on the left image\n",
    "        Left_nice = cv2.remap(imgL_gray,\n",
    "                              Left_Stereo_Map_x,\n",
    "                              Left_Stereo_Map_y,\n",
    "                              cv2.INTER_LANCZOS4,\n",
    "                              cv2.BORDER_CONSTANT,\n",
    "                              0)\n",
    "\n",
    "        # Applying stereo image rectification on the right image\n",
    "        Right_nice = cv2.remap(imgR_gray,\n",
    "                               Right_Stereo_Map_x,\n",
    "                               Right_Stereo_Map_y,\n",
    "                               cv2.INTER_LANCZOS4,\n",
    "                               cv2.BORDER_CONSTANT,\n",
    "                               0)\n",
    "\n",
    "        # Setting the updated parameters before computing disparity map\n",
    "        stereo.setNumDisparities(numDisparities)\n",
    "        stereo.setBlockSize(blockSize)\n",
    "        stereo.setPreFilterType(preFilterType)\n",
    "        stereo.setPreFilterSize(preFilterSize)\n",
    "        stereo.setPreFilterCap(preFilterCap)\n",
    "        stereo.setTextureThreshold(textureThreshold)\n",
    "        stereo.setUniquenessRatio(uniquenessRatio)\n",
    "        stereo.setSpeckleRange(speckleRange)\n",
    "        stereo.setSpeckleWindowSize(speckleWindowSize)\n",
    "        stereo.setDisp12MaxDiff(disp12MaxDiff)\n",
    "        stereo.setMinDisparity(minDisparity)\n",
    "\n",
    "        # Calculating disparity using the StereoBM algorithm\n",
    "        disparity = stereo.compute(Left_nice, Right_nice)\n",
    "        # NOTE: compute returns a 16bit signed single channel image,\n",
    "        # CV_16S containing a disparity map scaled by 16. Hence it\n",
    "        # is essential to convert it to CV_16S and scale it down 16 times.\n",
    "\n",
    "        # Converting to float32\n",
    "        disparity = disparity.astype(np.float32)\n",
    "\n",
    "        # Normalizing the disparity map\n",
    "        disparity = (disparity / 16.0 - minDisparity) / numDisparities\n",
    "\n",
    "        depth_map = M / (disparity)  # for depth in (cm)\n",
    "\n",
    "        mask_temp = cv2.inRange(depth_map, min_depth, max_depth)\n",
    "        depth_map = cv2.bitwise_and(depth_map, depth_map, mask=mask_temp)\n",
    "\n",
    "        obstacle_avoid()\n",
    "\n",
    "        cv2.resizeWindow(\"disp\", 700, 700)\n",
    "        cv2.imshow(\"disp\", disparity)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        CamL = cv2.VideoCapture(left_source, cv2.CAP_GSTREAMER)\n",
    "        CamR = cv2.VideoCapture(right_source, cv2.CAP_GSTREAMER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
